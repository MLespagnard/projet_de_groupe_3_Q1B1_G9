# projet_de_groupe_3_Q1B1_G9
# ğŸ“Œ Mini-Projet â€“ Classifieur NaÃ¯f BayÃ©sien (UNamur)

Ce dÃ©pÃ´t contient le code du mini-projet dâ€™informatique visant Ã  dÃ©velopper un **classifieur automatique de documents texte** utilisant une mÃ©thode inspirÃ©e du **Naive Bayes**.
Le but est de dÃ©terminer le **thÃ¨me le plus probable** dâ€™un fichier en se basant sur les fichiers dÃ©jÃ  classÃ©s.

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ labels.txt
â”œâ”€â”€ sorted/
â”‚   â”œâ”€â”€ comp.graphics/
â”‚   â”œâ”€â”€ sci.space/
â”‚   â”œâ”€â”€ talk.politics.guns/
â”‚   â””â”€â”€ ... (1 dossier par thÃ¨me contenant des fichiers dÃ©jÃ  classÃ©s)
â”œâ”€â”€ unsorted/
â”‚   â””â”€â”€ fichiers Ã  prÃ©dire
â””â”€â”€ result/
    â””â”€â”€ dossiers oÃ¹ seront placÃ©s les fichiers classÃ©s automatiquement
```

* **sorted/** : donnÃ©es dâ€™apprentissage, dÃ©jÃ  triÃ©es par thÃ¨me
* **unsorted/** : fichiers dont le thÃ¨me doit Ãªtre prÃ©dit
* **result/** : dossiers oÃ¹ le programme placera les fichiers selon leurs thÃ¨mes prÃ©dits
* **labels.txt** : journal listant pour chaque fichier :

  ```
  <nom> <thÃ¨me-prÃ©dit>
  ```

---

## ğŸ¯ Objectif du projet

Lâ€™objectif est de :

1. **Analyser les fichiers existants** dans `sorted/`
2. **Apprendre des probabilitÃ©s de mots par thÃ¨me**
3. **Classer automatiquement** les fichiers du dossier `unsorted/`
4. **Enregistrer le rÃ©sultat** dans `result/` et dans `labels.txt`

Aucune bibliothÃ¨que externe nâ€™est autorisÃ©e :
â¡ï¸ tout doit se faire uniquement avec le Python standard.

---

## ğŸ§  Principe du classifieur

### 1. PrÃ©traitement des textes

Pour chaque fichier :

* conversion en minuscules
* suppression de la ponctuation
* suppression des mots inutiles (stop words)
* sÃ©paration en mots

---

### 2. Apprentissage des probabilitÃ©s

Pour chaque thÃ¨me `T` :

* compter **le nombre total de fichiers** du thÃ¨me
* pour chaque mot `w`, compter **le nombre de fichiers du thÃ¨me contenant ce mot au moins une fois**

On calcule ensuite :

[
P(w \mid T) =
\frac{\text{nb de fichiers de T contenant w (ou 1 si jamais vu)}}{\text{nb total de fichiers de T}}
]

â¡ï¸ **RÃ¨gle technique du projet** :
Si un mot nâ€™apparaÃ®t jamais dans un thÃ¨me mais existe dans dâ€™autres, il compte comme ayant une occurrence fictive de 1.

Cela Ã©vite les probabilitÃ©s nulles.

---

### 3. Classification dâ€™un fichier

Pour chaque fichier de `unsorted/`, le programme :

1. lit et nettoie les mots
2. calcule un score pour chaque thÃ¨me basÃ© sur :

   * la probabilitÃ© que le mot apparaisse dans le thÃ¨me
   * la probabilitÃ© quâ€™il nâ€™apparaisse pas
3. sÃ©lectionne le thÃ¨me avec le score le plus Ã©levÃ©
4. dÃ©place le fichier dans `result/<theme>/`
5. enregistre la prÃ©diction dans `labels.txt`

---

## ğŸš€ ExÃ©cution

Ã€ la racine du projet :

```
python3 main.py
```

Le programme :

* apprend les probabilitÃ©s depuis `sorted/`
* classe les fichiers de `unsorted/`
* met Ã  jour `labels.txt`
* crÃ©e automatiquement la structure dans `result/`

---

## ğŸ“„ Exemple dâ€™entrÃ©e dans labels.txt

```
12345 sci.space
98765 comp.graphics
37261 talk.politics.guns
```

---

## ğŸ§ª Tests et validation

* Tester avec un fichier simple contenant un mot trÃ¨s frÃ©quent dans un thÃ¨me
* VÃ©rifier que les probabilitÃ©s sont bien calculÃ©es
* VÃ©rifier que les fichiers dÃ©placÃ©s correspondent aux thÃ¨mes annoncÃ©s
* ContrÃ´ler `labels.txt`

---

## ğŸ‘¥ Membres du groupe

*(Ajoute ici votre liste si besoin)*

---

## ğŸ“Œ Licence

Projet acadÃ©mique â€“ UniversitÃ© de Namur.
Usage strictement pÃ©dagogique.
